	virtual memory

Any computer system has one store of primary memory, which all processes running on the system share. However, raw sharing of memory between processes can have unintended, harmful consequences. It's an important security concern that the OS keep different processes' respective memory spaces distinct from each other, disallowing any process from accessing or modifying memory belonging to another process. Furthermore, in keeping with the abstraction barriers imposed by modern computer architectures, running processes require the illusion of access to the system's full, contiguously addressed, memory. To address these issues, memory is logically divided into two types - virtual memory and physical memory. Processes only ever access virtual memory, which refers to address spaces that don't actually map onto physical storage devices (i.e. RAM), but rather live on an abstraction layer on top of physical memory (which does address into physical RAM). Thus, virtual memory provides an illusory address space that's as large as all physical memory and in one contiguous block, despite physical memory being shared by many processes. Virtual memory is also useful in allowing the OS to control processes' access to memory in a more fine-grained way. For instance, it's able to more easily mark memory as read-only, write-only, etc., by simply verifying, in the MMU, if memory operations are valid under a given permissions scheme for that memory.

Since processes can only access virtual addresses, virtual addresses are mapped onto physical addresses. This process of dynamically (usually at runtime, though sometimes in the linking/loading phase) computing the physical address that a virtual address maps to, is called address translation, and is handled by a hardware circuit called the memory management unit (MMU). All references to primary memory are necessarily (i.e. are hardware constrained to do so) passed through the MMU. Thus, the MMU sits in between the CPU (and other hardware that might need to access memory) and main memory. Typically, the MMU is implemented in hardware as an integrated circuit that's built directly into the CPU. Its purpose is to translate the virtual addresses referenced by programs, and more directly by the processor, to physical addresses in memory. Its purpose is to translate the virtual addresses referenced by programs, and more directly by the processor, to physical addresses in memory. As such, the MMU is required to implement virtual memory management. For performance purposes, the MMU has a built-in fast memory cache, called the translation lookaside buffer (TLB), which stores recent translations of virtual addresses to physical addresses.


1. Base and Bounds
There are various implementations of memory management, though in practically all of them the operating system is assigned a fixed, unchanging section of memory, typically occupying the very first several memory addresses, for itself. An early and simple implementation of virtual memory is the base and bounds method, wherein each process is assigned a contiguous section of memory within which it's allowed to operate. As such, processes contain as part of their execution context (and hence stored in the PCB), two registers - one for storing the beginning (i.e. base) of their assigned memory section, and another for storing the section's size (i.e. bound). At runtime, addresses used by the process are mapped to physical addresses by adding the base to each address reference. Before hitting memory, the physical address is cross referenced against base + bound to verify that the reference is within the section owned by the process, throwing an exception otherwise. However, a major problem with base and bounds, and related methods, is that it's susceptible to memory fragmentation. Since processes are assigned memory in fixed-size chunks, which are expensive to shift around, it's possible for multiple processes to be assigned contiguously touching memory sections and then processes in the middle to terminate, leaving holes and gaps in the set of free memory. Having active memory sections live in the middle of free memory is problematic as it limits the size of future memory sections that can be allocated, even if there's enough total free memory to accommodate a request for memory.

2. Virtual Memory
More advanced virtual memory techniques make use of paging. Under this scheme, processes see their virtual address space as composed of contiguous memory segments, called pages. Physical memory is partitioned into blocks, called page frames, of the same size as virtual pages, with pages mapped one-to-one onto page frames. However, because page frames need not be contiguous in physical memory, even if there are holes in free memory, to allocate a long segment of new memory, the MMU can split the long segment into several page frames, and map the same number of contiguous (virtual) pages, as seen by the requesting process, to a number of non-contiguous, fragmented page frames. Though this isn't a perfect solution, as holes of free memory (in between allocated memory) smaller than the page size are still unable to be assigned and are essentially dead memory, the smaller the page size is, the more fine-grained the MMU's control of memory and hence the better assuaged the fragmentation problem. Further, the OS can swap old memory page frames that aren't currently in use or that haven't been accessed in a long time to disk, in a process known as paging. This frees up the address space available to a given process, and allows for the illusion of a full address space that isn't shared between multiple processes. When new processes are swapped into the CPU, their owned address space is loaded as part of their execution context, and their corresponding pages are retrieved from disk and into main memory. Because the mapping scheme here is more complex than a simple base-and-bound memory section, instead needing to support arbitrary mappings from pages to page frames, virtual memory implementations require an additional data structure, usually build into and managed by the MMU, called a page table. A page table is essentially a large hash table that maps (the address of) virtual pages to (the address of) physical page frames. Thus, when a virtual address needs to be translated, the MMU computes what page the address should be in and its corresponding offset within the page, looks up the address of the corresponding page frame in the page table, adds the offset to the retrieved physical address, and fetches the data at that physical address. When a virtual address that isn't mapped to anything by the MMU is accessed by a process, a page fault exception is raised. The page fault can be handled by looking for the corresponding page in disk and paging it in, though in some cases the page fault is a result of a genuinely bad memory call. The part of the OS that handles paging in and out of disk is called the paging supervisor, and is invoked on page faults. The responsibility of looking up pages from disk and storing them in page tables, and for clearing out old pages by swapping them to disk, falls to the paging supervisor.

Because one page table is required per address space, and processes have their own dedicated virtual address spaces, each process has its own page table. The smaller page sizes are, the larger a given page table is, and although any one individual page table usually isn't too large, every process needs their own page table and the amount of memory necessary to track all the page tables quickly grows very large. Moreover, although other memory constructs and elements of a process' execution context can be swapped out of memory and into disk, as necessary, when the process isn't running, page tables can't themselves be stored in disk seeing as they're what provide the mapping between virtual and physical memory itself; without the page tables in memory, there'd be no way to search for them in disk. This motivates the idea of multilevel page tables, which allow us to to decrease the size of a process' page table. We can simply track one additional "higher level" page table, which pages into sub-page-tables. The idea here is to "unflatten" one large page table into a tree-structure of page tables that index into "child" page tables. Although in the worst case, this uses slightly more memory, since we might require all the sub-page-tables, which together take up as much memory as a single-level page table, in addition to the higher-level page table, in the average case we only need to load sub-page-tables from disk when necessary, leaving the rest stored in disk. In practice, most modern implementations use three- or four-level page tables, which offers significant advantages as on average address spaces are so large and locality of reference so high that memory tends to be quite sparse, only necessitating a few lower-order page tables to be in memory at any given time. Of course, this disadvantage to multilevel page tables is that each memory reference now requires multiple (specifically, equal to the depth of the page table tree) memory accesses, one per page table level, before the data is actually read.

3. Segmentation
Modern address spaces tend to be divided into variable-length segments that grow as needed. These segments correspond to logical subdivisions of memory (i.e. code vs data vs heap vs stack, etc.), and so are different in purpose from pages. Thus, the main advantage to segmentation is the ability to divide our address space into multiple linear address subspaces, which logically correspond to different uses of that memory. Typically each segment will employ paging to reduce fragmentation.